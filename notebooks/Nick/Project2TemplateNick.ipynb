{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![for sale image, from https://time.com/5835778/selling-home-coronavirus/](https://api.time.com/wp-content/uploads/2020/05/selling-home-coronavirus.jpg?w=800&quality=85)\n",
    "\n",
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A one-paragraph overview of the project, including the business problem, data, methods, results and recommendations.\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Who are your stakeholders?\n",
    "- What are your stakeholders' pain points related to this project?\n",
    "- Why are your predictions important from a business perspective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholders: small real estate company who advises families on selling their homes\n",
    "### Pain points: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Where did the data come from, and how do they relate to the data analysis questions?\n",
    "- What do the data represent? Who is in the sample and what variables are included?\n",
    "- What is the target variable?\n",
    "- What are the properties of the variables you intend to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/kc_house_data.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm focusing on specific house features\n",
    "rel_cols = ['id','price','sqft_living','sqft_lot','sqft_above','sqft_basement',\n",
    "            'floors','bedrooms','bathrooms']\n",
    "rel_cols_log = ['id','price','sqft_living','sqft_lot','sqft_above']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan = data[rel_cols]\n",
    "datan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.loc[datan['sqft_basement'] == '?','sqft_basement'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryfloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan['sqft_basement'] = datan['sqft_basement'].map(tryfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datan.columns:\n",
    "    print(f'\\n{col}:\\n')\n",
    "    print(datan.sort_values(by=col,ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33 bedrooms is pretty crazy and not highly correlated with a high price. I'll remove that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan = datan[datan['bedrooms'] != 33]\n",
    "datan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(datan);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lot of these features look like they could use some log processing. Let's try it with the whole thing to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanlog = pd.DataFrame()\n",
    "for col in rel_cols_log:\n",
    "    if col == 'id':\n",
    "        datanlog[col] = datan[col]\n",
    "        continue\n",
    "    if col == 'sqft_basement':\n",
    "        continue\n",
    "    datanlog[f'{col}_log'] = datan[col].map(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanlog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanlog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanlog.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(datanlog);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(2,3, figsize=(20,20))\n",
    "for i, col in enumerate(datanlog.columns):\n",
    "    sns.histplot(data=datanlog, x=col, kde=True, ax=axes[i//3,i%3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(3,3, figsize=(20,20))\n",
    "for i, col in enumerate(datan.columns):\n",
    "    sns.histplot(data=datan, x=col, kde=True, ax=axes[i//3,i%3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanfeat = datan.drop(columns='price')\n",
    "datanfeat.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanlogfeat = datanlog.drop(columns='price_log')\n",
    "datanlogfeat.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datantot = pd.merge(datan,datanlog,on='id')\n",
    "datantot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datantot.corr().sort_values('price_log',ascending=False)['price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datantotfeat = datantot.drop(columns=['price_log','price'])\n",
    "dtfc = datantotfeat.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "dtfc['col_pairs'] = list(zip(dtfc.level_0,dtfc.level_1))\n",
    "dtfc['same'] = dtfc['col_pairs'].map(lambda x: (x[0] in x[1]) or (x[1] in x[0]))\n",
    "dtfc['col_pairs'] = dtfc['col_pairs'].map(lambda x:sorted(list(x)))\n",
    "dtfc.set_index(['col_pairs'],inplace=True)\n",
    "dtfc = dtfc[dtfc['same'] == False]\n",
    "dtfc.drop(columns=['level_0','level_1','same'],inplace=True)\n",
    "dtfc.columns = ['C']\n",
    "dtfc.drop_duplicates(inplace=True)\n",
    "dtfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build models.\n",
    "### Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datantot.drop(columns=['price_log','price'])\n",
    "\n",
    "Xpr_train, Xpr_test, ypr_train, ypr_test = \\\n",
    "train_test_split(X, datantot['price'], test_size=0.33, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, datantot['price_log'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_sc, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_sc, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_mean = y_train.mean()\n",
    "baseline_train_pred = [train_target_mean] * len(y_train)\n",
    "baseline_test_pred = [train_target_mean] * len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_tr, y_te, y_tr_pr, y_te_pr):\n",
    "    '''\n",
    "    Evaluates the error between the model predictions and the real values for both\n",
    "    training and test sets.\n",
    "    \n",
    "    Arguments:\n",
    "    y_tr - array-like\n",
    "        Actual values for output variable, for the training set\n",
    "    y_tr_pr - array-like\n",
    "        Predicted values for output variable, for the training set\n",
    "    y_te - array-like\n",
    "        Actual values for output variable, for the test set\n",
    "    y_te_pr - array-like\n",
    "        Predicted values for output variable, for the test set\n",
    "    \n",
    "    Returns:\n",
    "    R2 scores for Train and Test sets\n",
    "    RMSE for Train and Test sets\n",
    "    MAE for Train and Test sets\n",
    "    '''\n",
    "    print(f'Train R2 score: {r2_score(y_tr, y_tr_pr)} ')\n",
    "    print(f'Test R2 score: {r2_score(y_te, y_te_pr)} ')\n",
    "    print('<><><><><>')\n",
    "    print(f'Train RMSE (ln): {mean_squared_error(y_tr, y_tr_pr, squared=False)} ')\n",
    "    print(f'Test RMSE (ln): {mean_squared_error(y_te, y_te_pr, squared=False)} ')\n",
    "    print('<><><><><>')\n",
    "    print(f'Train MAE (ln): {mean_absolute_error(y_tr, y_tr_pr)} ')\n",
    "    print(f'Test MAE (ln): {mean_absolute_error(y_te, y_te_pr)} ')\n",
    "    \n",
    "    # residuals\n",
    "    train_res = y_tr - y_tr_pr\n",
    "    test_res = y_te - y_te_pr\n",
    "    \n",
    "    # scatter plot of residuals\n",
    "    print(\"\\nScatter of residuals:\")\n",
    "    plt.scatter(y_tr_pr, train_res, label='Train')\n",
    "    plt.scatter(y_te_pr, test_res, label='Test')\n",
    "    plt.axhline(y=0, color='purple', label='0')\n",
    "    plt.xlabel(\"Predicted Price\")\n",
    "    plt.ylabel(\"Residual Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"QQ Plot of residuals:\")\n",
    "    fig, ax = plt.subplots()\n",
    "    sm.qqplot(train_res, ax=ax, marker='.', color='r', label='Train', alpha=0.3, line='s')\n",
    "    sm.qqplot(test_res, ax=ax,  marker='.', color='g', label='Test', alpha=0.3)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train, y_test, baseline_train_pred, baseline_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smols(X,y,cols=cols):\n",
    "    Xcol = X[cols]\n",
    "    shmod = sm.OLS(endog=y, exog=sm.add_constant(Xcol)).fit()\n",
    "    return shmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sqft_living_log']\n",
    "smols(X_train,y_train,cols).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linpreds(X_tr_scaled, y_tr, X_te_scaled):\n",
    "    '''\n",
    "    Uses Linear Regression to generate output predictions given training and test inputs.\n",
    "    Arguments:\n",
    "    X_tr_scaled - dataframe\n",
    "        Input variables and values for the training set\n",
    "    y_tr - array-like\n",
    "        Actual values for output variable, for the training set\n",
    "    X_te_scaled - dataframe\n",
    "        Input variables and values for the test set\n",
    "    Returns:\n",
    "    Output (y) prediction arrays:\n",
    "        train, test\n",
    "    '''\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_tr_scaled, y_tr)\n",
    "    return lr.predict(X_tr_scaled), lr.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smols(X_train_scaled,y_train,\\\n",
    "      cols=['sqft_living_log','bathrooms','bedrooms','floors']).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr1, X_te1 = X_train_scaled[['sqft_living_log']], X_test_scaled[['sqft_living_log']]\n",
    "X_tr2, X_te2 = X_train_scaled[['sqft_living_log','bathrooms']],\\\n",
    "               X_test_scaled[['sqft_living_log','bathrooms']]\n",
    "X_tr3, X_te3 = X_train_scaled[['sqft_living_log','bathrooms','bedrooms']],\\\n",
    "               X_test_scaled[['sqft_living_log','bathrooms','bedrooms']]\n",
    "X_tr4, X_te4 = X_train_scaled[['sqft_living_log','bathrooms','bedrooms','floors']],\\\n",
    "               X_test_scaled[['sqft_living_log','bathrooms','bedrooms','floors']]\n",
    "\n",
    "trp1, tep1 = linpreds(X_tr1, y_train, X_te1)\n",
    "trp2, tep2 = linpreds(X_tr2, y_train, X_te2)\n",
    "trp3, tep3 = linpreds(X_tr3, y_train, X_te3)\n",
    "trp4, tep4 = linpreds(X_tr4, y_train, X_te4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train, y_test, trp4, tep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train, y_test, trp3, tep3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train, y_test, trp2, tep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train, y_test, trp1, tep1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features\n",
    "As seen above, we get only modest improvements in R2 and error calculations, but let's see if we can improve this with interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datantot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpf = datantot.drop(columns=['price_log','price','id','sqft_basement','sqft_living', 'sqft_lot', 'sqft_above'])\n",
    "\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "pf.fit(Xpf)\n",
    "Xpdf = pd.DataFrame(pf.transform(Xpf),\\\n",
    "                   columns=pf.get_feature_names(input_features=Xpf.columns))\n",
    "\n",
    "Xpf_train, Xpf_test, ypf_train, ypf_test = \\\n",
    "train_test_split(Xpdf, datantot['price_log'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfscaler = StandardScaler()\n",
    "pfscaler.fit(Xpf_train)\n",
    "Xpf_train_scaled = pfscaler.transform(Xpf_train)\n",
    "Xpf_test_scaled = pfscaler.transform(Xpf_test)\n",
    "Xpf_train_scaled = pd.DataFrame(Xpf_train_scaled, columns=Xpf_train.columns, index=Xpf_train.index)\n",
    "Xpf_test_scaled = pd.DataFrame(Xpf_test_scaled, columns=Xpf_test.columns, index=Xpf_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pftrp1, pftep1 = linpreds(Xpf_train_scaled, ypf_train, Xpf_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ypf_train, ypf_test, pftrp1, pftep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpf_train_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smXpf = Xpf_train_scaled.drop(columns='1')\n",
    "pfsm = smols(smXpf, ypf_train, cols=smXpf.columns)\n",
    "pfsm_df = pfsm.params.reset_index()\n",
    "pfsm_df = pfsm_df.merge(pfsm.pvalues.reset_index(), on='index')\n",
    "pfsm_df = pfsm_df.set_index('index')\n",
    "pfsm_df.columns = ['coef','p_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfsm_df.sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfsm_df.sort_values('p_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Were there variables you dropped or created?\n",
    "- How did you address missing values or outliers?\n",
    "- Why are these choices appropriate given the data and the business problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How did you analyze the data to arrive at an initial approach?\n",
    "- How did you iterate on your initial approach to make it better?\n",
    "- Why are these choices appropriate given the data and the business problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation of each model should accompany the creation of each model, and you should be sure to evaluate your models consistently.\n",
    "\n",
    "Evaluate how well your work solves the stated business problem. \n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How do you interpret the results?\n",
    "- How well does your model fit your data? How much better is this than your baseline model? Is it over or under fit?\n",
    "- How well does your model/data fit any modeling assumptions?\n",
    "\n",
    "For the final model, you might also consider:\n",
    "\n",
    "- How confident are you that your results would generalize beyond the data you have?\n",
    "- How confident are you that this model would benefit the business if put into use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Understanding\n",
    "\n",
    "- What does a baseline, model-less prediction look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to arrive at a baseline prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First $&(@# Model\n",
    "\n",
    "Before going too far down the data preparation rabbit hole, be sure to check your work against a first 'substandard' model! What is the easiest way for you to find out how hard your problem is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here for your first 'substandard' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your first 'substandard' model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Iterations\n",
    "\n",
    "Now you can start to use the results of your first model to iterate - there are many options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to iteratively improve your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Final' Model\n",
    "\n",
    "In the end, you'll arrive at a 'final' model - aka the one you'll use to make your recommendations/conclusions. This likely blends any group work. It might not be the one with the highest scores, but instead might be considered 'final' or 'best' for other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to show your final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- What would you recommend the business do as a result of this work?\n",
    "- What are some reasons why your analysis might not fully solve the business problem?\n",
    "- What else could you do in the future to improve this project (future work)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
